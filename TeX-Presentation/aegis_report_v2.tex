\documentclass{llncs}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{amsmath,amssymb}
\usepackage{listings}
\usepackage{url}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{booktabs}
\usepackage{array}
\usepackage{tabularx}

% Code listing style
\lstset{
  basicstyle=\ttfamily\small,
  breaklines=true,
  frame=single,
  backgroundcolor=\color{gray!10},
  keywordstyle=\color{blue},
  stringstyle=\color{red!70!black},
  commentstyle=\color{green!50!black},
  numbers=left,
  numberstyle=\tiny\color{gray},
  numbersep=5pt
}

\begin{document}

\title{NMS(Network monitor system): Computer Network Monitor and Security Incidents Prevention System}

\author{Negura Teodor-Alexandru}
\institute{University ``Alexandru Ioan Cuza'' of Iași,\\
Faculty of Computer Science\\
\email{}}

\maketitle
\thispagestyle{empty}
\pagestyle{empty}

\begin{abstract}
This paper presents the design and implementation of NMS, a modular platform for monitoring computer networks and preventing security incidents. The system employs a three-tier architecture consisting of lightweight endpoint agents, client hubs with native graphical interfaces, and a centralised server performing machine learning-based anomaly detection using ONNX Runtime and LogBERT. The platform supports both custom agents and third-party syslog sources (RFC~5424), enabling integration with existing network infrastructure. Each client operates as an autonomous monitoring hub for its local network while maintaining privacy isolation at the server level. The architecture emphasises high performance through C++ implementation, secure communication via TLS, and real-time threat visualisation through Dear ImGui dashboards. This work demonstrates how modern machine learning techniques can be integrated into traditional network monitoring systems while maintaining modularity, extensibility, and strict privacy boundaries between multiple users.

\keywords{Network monitoring \and Security incidents \and Syslog RFC~5424 \and ONNX Runtime \and LogBERT \and C++ \and Client--Server \and Anomaly detection}
\end{abstract}

%==============================================================================
\section{Introduction}
%==============================================================================

The proliferation of connected devices and the increasing sophistication of cyber threats have made network monitoring an essential component of modern IT infrastructure. Traditional approaches relying on signature-based detection and manual log analysis are no longer sufficient to address zero-day exploits, advanced persistent threats, and the sheer volume of security events generated by contemporary networks.

The goal of this project is to build a state-of-the-art network monitoring and security incident prevention platform based on a three-tier architecture. The system addresses the problem of centralising network intelligence while respecting privacy boundaries between different users and networks. Unlike centralised solutions where all data flows to a single administrator, NMS enables each client to monitor their own network infrastructure independently, with the central server providing computational resources for machine learning inference without exposing data across client boundaries.

The platform operates on the following principles. First, each client acts as a hub for their local network, collecting events from both custom agents and standard syslog sources. Second, the central server performs heavy computational tasks (ONNX/LogBERT inference) and returns only the results relevant to each client. Third, privacy isolation ensures that Client~A cannot access data belonging to Client~B, enforced through public IP identification. Fourth, modularity allows new data sources, agents, and analysis components to be added without redesigning the system.

A key innovation is the integration of LogBERT, a transformer-based language model specifically trained for log anomaly detection, executed through ONNX Runtime for high-performance C++ inference. This enables the detection of subtle attack patterns that would escape traditional rule-based systems.

%==============================================================================
\section{Applied Technologies}
%==============================================================================

The technology stack was carefully selected to satisfy functional requirements (network monitoring, anomaly detection, multi-user support) and non-functional requirements (performance, security, modularity, ease of deployment).

\textbf{C++20} serves as the implementation language for all three components: server, client, and agent. C++ provides deterministic memory management, zero-cost abstractions, and direct access to system APIs essential for network programming and syslog collection. The use of modern C++20 features (concepts, ranges, coroutines where appropriate) ensures code clarity without sacrificing performance.

\textbf{TCP with TLS (OpenSSL)} provides the transport layer for client--server communication. TCP guarantees ordered, reliable delivery of monitoring events, while TLS 1.3 encryption protects against eavesdropping and man-in-the-middle attacks. The OpenSSL library, compiled statically into the binaries, handles certificate validation and key exchange.

\textbf{Syslog (RFC~5424)} defines the standard format for log messages. The platform natively accepts syslog from any compliant source on UDP/TCP port~514, enabling integration with third-party software such as rsyslog, syslog-ng, Filebeat, and network equipment (routers, firewalls, switches). This satisfies the requirement for testing with third-party agents.

\textbf{JSON with Length-Prefix Framing} serves as the application-level message format. JSON provides human-readable, self-describing messages that simplify debugging and Wireshark analysis. Each message is prefixed with a 4-byte length field (network byte order) to enable efficient parsing over the TCP stream without delimiter scanning.

\textbf{ONNX Runtime} executes the pre-trained LogBERT anomaly detection model. ONNX (Open Neural Network Exchange) provides a framework-agnostic format for machine learning models, while ONNX Runtime offers optimised C++ inference with optional CUDA acceleration. This allows the server to classify thousands of log events per second.

\textbf{LogBERT} is a transformer-based model specifically designed for log anomaly detection. Pre-trained on large corpora of system logs, LogBERT understands the semantic structure of log messages and can identify anomalies that deviate from learned patterns, including novel attack vectors not covered by traditional signatures.

\textbf{SQLite} provides lightweight, embedded database functionality. On the client side, SQLite stores file integrity baselines, agent configuration, and cached results from the server. On the server side, SQLite stores processed events and alerts, partitioned by client public IP for privacy isolation.

\textbf{Dear ImGui} powers the native graphical dashboard on the client. Unlike web-based interfaces requiring REST APIs and browser dependencies, Dear ImGui renders directly through OpenGL, providing immediate-mode GUI with minimal latency. The dashboard displays real-time alerts, endpoint status, statistics, and log streams.

\textbf{Docker} containerises the server component, encapsulating ONNX Runtime, the LogBERT model, OpenSSL, and all dependencies into a reproducible deployment unit. Clients and agents run as native binaries without containerisation to minimise resource overhead on endpoints.

\textbf{nlohmann/json} is a header-only C++ library for JSON parsing and serialisation. Its intuitive API and excellent performance make it the standard choice for modern C++ projects requiring JSON support.

%==============================================================================
\section{Application Structure}
%==============================================================================

The system comprises three distinct components, each compiled as a separate binary from a shared CMake codebase. Figure~\ref{fig:architecture} illustrates the high-level architecture.

%--- Placeholder for architecture diagram ---
\begin{figure}[ht]
  \centering
  \includegraphics[width=\textwidth]{images/1.png}
  \caption{High-level architecture of NMS showing the three-tier structure: Server, Clients, and Endpoint Agents.}
  \label{fig:architecture}
\end{figure}

\subsection{Server Component}

The server runs inside a Docker container on the operator's infrastructure (for this thesis, the author's machine). It accepts TLS connections from multiple clients on port~1514 and performs the following functions:

\begin{itemize}
  \item \textbf{Connection Management}: A dedicated listener thread accepts incoming TLS connections, extracts the client's public IP address for identification, and dispatches each connection to a worker thread from the pool.
  \item \textbf{Protocol Handling}: Worker threads parse incoming JSON messages, validate their structure, and route them to the appropriate processing pipeline based on message type (REGISTER, BATCH\_EVENT, HEARTBEAT).
  \item \textbf{Event Batching}: Incoming events are accumulated into batches of 32--64 entries per client before being forwarded to the inference pipeline, optimising throughput for the LogBERT model.
  \item \textbf{ONNX Inference}: A dedicated inference thread tokenises batched log messages using the LogBERT vocabulary and executes the ONNX model to classify each event as normal or anomalous.
  \item \textbf{Storage}: Processed events and detected anomalies are stored in SQLite, keyed by the client's public IP address. This ensures strict privacy isolation---queries for Client~A's data never return Client~B's records.
  \item \textbf{Response Generation}: Results (alerts, statistics) are serialised as JSON and transmitted back to the originating client over the same TLS connection.
\end{itemize}

The server does not include a graphical interface; all visualisation occurs on the client side.

\subsection{Client Component}

The client is the central piece of the architecture from the user's perspective. Each user runs one client instance on their primary machine (e.g., laptop), which serves as the hub for their entire local network. The client binary integrates four modules:

\begin{itemize}
  \item \textbf{Agent Module}: Monitors the local machine itself, collecting syslog entries from \texttt{/dev/log} (Linux) or the Event Log (Windows), tracking file integrity through cryptographic hashes stored in SQLite, and observing process creation and network connections.
  \item \textbf{Hub Module}: Listens for incoming connections from endpoint agents within the local network. Two listener ports are exposed:
    \begin{itemize}
      \item \textit{Port 1515 (TCP)}: Accepts connections from custom NMS agents using the JSON protocol with length-prefix framing.
      \item \textit{Port 514 (UDP/TCP)}: Accepts standard syslog messages (RFC~5424) from third-party sources such as rsyslog, routers, firewalls, and other network equipment.
    \end{itemize}
  \item \textbf{Network Module}: Maintains a persistent TLS connection to the central server, batches collected events (both self-generated and received from endpoints), transmits them to the server, and receives processed results.
  \item \textbf{UI Module}: Renders the Dear ImGui dashboard, displaying real-time alerts, endpoint status, event statistics, and live log streams. The UI reads directly from a local cache populated by responses from the server, requiring no REST API or web server.
\end{itemize}

Figure~\ref{fig:client} shows the internal structure of the client binary.

\begin{figure}[ht]
  \centering
  \includegraphics[width=\textwidth]{images/2.png}
  \caption{Internal architecture of the client binary showing the four integrated modules.}
  \label{fig:client}
\end{figure}

\subsection{Agent Component}

The agent is a lightweight binary designed for deployment on endpoint devices within the client's network (desktops, servers, IoT devices). Its sole responsibility is collecting local events and forwarding them to the client hub. The agent has no graphical interface and minimal resource footprint.

Key characteristics of the agent include static linking to eliminate runtime dependencies, a single configuration file specifying the hub address and port, automatic reconnection logic with exponential backoff, and local buffering in SQLite when the hub is temporarily unreachable.

The agent communicates with the client hub over plain TCP (port~1515) using the JSON protocol. TLS is not used for agent--hub communication because both parties reside on the same local network, and the overhead would be unnecessary for constrained devices.

\subsection{Third-Party Integration}

A critical requirement is the ability to receive logs from third-party software without installing custom agents. This is achieved through the standard syslog interface (port~514). Any device or software capable of emitting RFC~5424 syslog can send events to the client hub.

Example configurations for common third-party sources:

\textbf{rsyslog (Linux):} Add to \texttt{/etc/rsyslog.conf}:
\begin{lstlisting}[language=bash]
*.* @@192.168.1.100:514   # TCP
*.* @192.168.1.100:514    # UDP
\end{lstlisting}

\textbf{Network Router:} Configure in the administration panel:
\begin{lstlisting}
Syslog Server: 192.168.1.100
Syslog Port: 514
Protocol: UDP
\end{lstlisting}

This dual-input architecture (custom agents on port~1515, standard syslog on port~514) ensures maximum flexibility and compatibility with existing infrastructure.

\subsection{Data Flow Summary}

The complete data flow from endpoint to dashboard proceeds as follows:

\begin{enumerate}
  \item Endpoint agent collects syslog entries and local events.
  \item Agent serialises events as JSON and sends to client hub (port~1515).
  \item Third-party sources send RFC~5424 syslog to client hub (port~514).
  \item Client hub aggregates events from all sources, including self-monitoring.
  \item Client batches events and transmits to server over TLS (port~1514).
  \item Server identifies client by public IP, parses events, runs ONNX inference.
  \item Server stores results in SQLite (partitioned by client IP).
  \item Server returns alerts and statistics to client.
  \item Client caches results and renders in Dear ImGui dashboard.
\end{enumerate}

Figure~\ref{fig:dataflow} illustrates this pipeline.

\begin{figure}[ht]
  \centering
  \includegraphics[width=\textwidth]{images/3.png}
  \caption{Data flow from endpoint agents through the client hub to the server and back to the client UI.}
  \label{fig:dataflow}
\end{figure}

\subsection{Privacy Isolation Model}

Multiple clients can connect to the same server simultaneously, each monitoring their own network. Privacy is enforced through public IP identification: the server extracts the source IP from each TLS connection and uses it as a partition key for all database operations.

When Client~A (public IP \texttt{86.123.45.67}) requests their data, the server executes:
\begin{lstlisting}[language=SQL]
SELECT * FROM events WHERE client_ip = '86.123.45.67';
SELECT * FROM alerts WHERE client_ip = '86.123.45.67';
\end{lstlisting}

Client~B (public IP \texttt{91.200.10.20}) receives only their own records, with no visibility into Client~A's data. This simple yet effective mechanism provides baseline privacy isolation suitable for the thesis demonstration. Future enhancements could add authentication tokens for stronger identity verification.

\subsection{Deployment Architecture}

Table~\ref{tab:deployment} summarises the deployment model for each component.

\begin{table}[ht]
\centering
\caption{Deployment architecture for NMS components.}
\label{tab:deployment}
\begin{tabular}{@{}llll@{}}
\toprule
\textbf{Component} & \textbf{Build} & \textbf{Deployment} & \textbf{Dependencies} \\
\midrule
Server & CMake $\rightarrow$ C++ & Docker container & ONNX Runtime, OpenSSL, SQLite \\
Client & CMake $\rightarrow$ C++ & Native binary & OpenSSL, SQLite, Dear ImGui, OpenGL \\
Agent & CMake $\rightarrow$ C++ & Native binary (static) & SQLite (embedded) \\
\bottomrule
\end{tabular}
\end{table}

%==============================================================================
\section{Communication Protocol}
%==============================================================================

Communication occurs at two levels: agent-to-hub (LAN) and client-to-server (WAN). Both use JSON as the message format but differ in transport characteristics.

\subsection{Message Framing}

All JSON messages are transmitted using length-prefix framing to enable efficient parsing over TCP streams. Each message consists of:

\begin{itemize}
  \item \textbf{Length Field}: 4 bytes, unsigned 32-bit integer in network byte order (big-endian), specifying the length of the following JSON payload in bytes.
  \item \textbf{Payload}: Variable-length UTF-8 encoded JSON string.
\end{itemize}

This approach avoids the need to scan for delimiter characters and handles JSON strings containing newlines correctly.

\begin{lstlisting}[caption={Message frame structure.}]
+----------------+----------------------------+
| 4 bytes        | N bytes                    |
| Length (N)     | JSON Payload               |
| (big-endian)   | {"type":"EVENT",...}       |
+----------------+----------------------------+
\end{lstlisting}

\subsection{Message Types}

The protocol defines six message types, each identified by the \texttt{type} field:

\begin{lstlisting}[caption={Generic message schema.},label={lst:schema}]
{
  "type": "REGISTER" | "HEARTBEAT" | "BATCH_EVENT" | 
          "RESULTS" | "COMMAND" | "ACK",
  "timestamp": "2025-11-28T14:30:00Z",
  "payload": { ... }
}
\end{lstlisting}

\textbf{REGISTER}: Sent by the client upon initial connection to the server, or by an agent upon connection to the hub. Contains identification information.

\begin{lstlisting}[caption={REGISTER message from client to server.}]
{
  "type": "REGISTER",
  "timestamp": "2025-11-28T14:30:00Z",
  "payload": {
    "client_version": "1.0.0",
    "hostname": "user-laptop",
    "os": "Linux 6.1.0",
    "endpoints_count": 3
  }
}
\end{lstlisting}

\textbf{HEARTBEAT}: Sent periodically (default: every 30 seconds) to indicate liveness and provide status metrics.

\begin{lstlisting}[caption={HEARTBEAT message.}]
{
  "type": "HEARTBEAT",
  "timestamp": "2025-11-28T14:31:00Z",
  "payload": {
    "uptime_seconds": 3600,
    "events_queued": 12,
    "endpoints_connected": 3
  }
}
\end{lstlisting}

\textbf{BATCH\_EVENT}: Transmitted by the client to the server containing aggregated events from all sources (self-agent, custom agents, third-party syslog).

\begin{lstlisting}[caption={BATCH\_EVENT message with multiple events.}]
{
  "type": "BATCH_EVENT",
  "timestamp": "2025-11-28T14:30:05Z",
  "payload": {
    "events": [
      {
        "source": "self",
        "syslog": {
          "facility": 4,
          "severity": 5,
          "app": "sshd",
          "pid": 12345,
          "message": "Failed password for root from 10.0.0.50"
        }
      },
      {
        "source": "192.168.1.101",
        "syslog": {
          "facility": 10,
          "severity": 6,
          "app": "kernel",
          "pid": 0,
          "message": "TCP: request_sock_TCP: Possible SYN flooding"
        }
      }
    ]
  }
}
\end{lstlisting}

\textbf{RESULTS}: Sent by the server to the client containing processed alerts and statistics.

\begin{lstlisting}[caption={RESULTS message from server.}]
{
  "type": "RESULTS",
  "timestamp": "2025-11-28T14:30:06Z",
  "payload": {
    "alerts": [
      {
        "id": "alert-001",
        "severity": "HIGH",
        "source": "192.168.1.101",
        "category": "brute_force",
        "message": "Multiple failed SSH attempts detected",
        "confidence": 0.94
      }
    ],
    "stats": {
      "events_processed": 64,
      "anomalies_detected": 1,
      "processing_time_ms": 45
    }
  }
}
\end{lstlisting}

\textbf{COMMAND}: Initiated by the server (or through future administrative interface) to request an action on the client or a specific endpoint.

\begin{lstlisting}[caption={COMMAND message.}]
{
  "type": "COMMAND",
  "timestamp": "2025-11-28T14:32:00Z",
  "payload": {
    "command_id": "cmd-123",
    "action": "request_fim_report",
    "target": "192.168.1.101"
  }
}
\end{lstlisting}

\textbf{ACK}: Acknowledgement confirming receipt and processing of REGISTER or COMMAND messages.

\begin{lstlisting}[caption={ACK message.}]
{
  "type": "ACK",
  "timestamp": "2025-11-28T14:30:01Z",
  "payload": {
    "status": "ok",
    "message": "Registration successful",
    "config": {
      "heartbeat_interval": 30,
      "batch_size": 64
    }
  }
}
\end{lstlisting}

\subsection{Protocol State Machine}

Figure~\ref{fig:statemachine} shows the state transitions for a client connection.

\begin{figure}[ht]
  \centering
  \includegraphics[width=0.4\textwidth]{images/4.png}
  \caption{State machine for client--server connection lifecycle.}
  \label{fig:statemachine}
\end{figure}



The connection lifecycle proceeds as follows:
\begin{enumerate}
  \item Client initiates TCP connection to server on port 1514.
  \item TLS handshake establishes encrypted channel.
  \item Client sends REGISTER message with identification.
  \item Server validates and responds with ACK containing configuration.
  \item Connection enters Active state; client sends HEARTBEAT and BATCH\_EVENT.
  \item Server sends RESULTS after processing batches.
  \item On connection loss, client enters Reconnecting state with exponential backoff.
\end{enumerate}

\subsection{Port Assignments}

Table~\ref{tab:ports} summarises the network ports used by the platform.

\begin{table}[ht]
\centering
\caption{Network port assignments.}
\label{tab:ports}
\begin{tabular}{@{}lllll@{}}
\toprule
\textbf{Port} & \textbf{Protocol} & \textbf{Direction} & \textbf{Encryption} & \textbf{Purpose} \\
\midrule
1514 & TCP & Client $\rightarrow$ Server & TLS 1.3 & Primary communication \\
1515 & TCP & Agent $\rightarrow$ Client Hub & None (LAN) & Custom agent protocol \\
514 & UDP/TCP & Third-party $\rightarrow$ Client Hub & None (LAN) & Standard syslog \\
\bottomrule
\end{tabular}
\end{table}

%==============================================================================
\section{Real World Use Cases}
%==============================================================================

This section presents six scenarios demonstrating the platform's capabilities: three successful executions and three failure handling cases.

\subsection{Successful Scenarios}

\subsubsection{Scenario 1: Brute-Force SSH Detection}

A user deploys NMS on their home network. The client runs on their laptop, and agents are installed on a desktop PC and a Raspberry Pi server.

An attacker on the internet attempts to brute-force the SSH service on the Raspberry Pi, which is exposed through port forwarding. The agent on the Pi collects authentication failure events from \texttt{/var/log/auth.log} and forwards them to the client hub. The client batches these events and transmits them to the server.

The LogBERT model, having been trained on patterns of authentication attacks, identifies the sequence of ``Failed password'' messages as anomalous. The server returns a HIGH severity alert to the client, which displays it prominently in the ImGui dashboard. The user sees the alert within seconds of the attack beginning and can take action (block the IP at the router, disable password authentication).

\subsubsection{Scenario 2: Third-Party Router Integration}

A small business owner wants to monitor their network without installing custom software on every device. They configure their enterprise router to send syslog to the NMS client running on their workstation.

The router sends RFC~5424 messages to port~514 (UDP) whenever significant events occur: firewall blocks, DHCP leases, VPN connections. The client hub receives these standard syslog messages, parses them according to RFC~5424, normalises them into the internal JSON format, and forwards them to the server.

The LogBERT model detects an unusual pattern: repeated firewall blocks from an internal IP address attempting to reach external command-and-control servers. This indicates a potentially compromised device. The alert appears on the dashboard with the source IP, allowing the owner to isolate the device for investigation.

\subsubsection{Scenario 3: File Integrity Monitoring}

A developer uses NMS to monitor their web server. The agent is configured with a list of critical files: \texttt{/etc/passwd}, \texttt{/etc/shadow}, \texttt{nginx.conf}, and the web application directory.

On initial startup, the agent computes SHA-256 hashes of all monitored files and stores them in local SQLite. Every 5 minutes, it recomputes hashes and compares against the baseline. When the developer legitimately updates \texttt{nginx.conf}, the agent detects the change and sends an EVENT to the hub.

The server's LogBERT model considers the context: a configuration file changed during business hours from an authorised user session. The confidence score for malicious activity is low (0.12). The event is logged but not flagged as a high-priority alert.

Later, an attacker exploits a vulnerability and modifies \texttt{/etc/passwd} at 3:00 AM. The agent detects this change. LogBERT, trained to recognise suspicious patterns (system file modification, unusual hour, no preceding legitimate administrative activity), assigns a high anomaly score (0.97). A CRITICAL alert is generated immediately.

\subsection{Failure Scenarios}

\subsubsection{Scenario 4: Network Disconnection Handling}

A user is monitoring their home network when their internet connection fails. The client loses its TLS connection to the server.

The client's network module detects the connection loss and enters the Reconnecting state. It attempts to reconnect with exponential backoff (1s, 2s, 4s, 8s, up to 5 minutes maximum). During this period, the hub continues to receive events from local agents and third-party sources.

Events are queued in a local buffer (up to 10,000 entries). The UI displays a ``Server Disconnected'' indicator but continues to show the last known state and locally collected events. When the connection is restored, queued events are transmitted in batches, ensuring no data loss.

\subsubsection{Scenario 5: Malformed Message Rejection}

A misconfigured third-party device sends malformed syslog messages to the client hub—perhaps binary data or incorrectly formatted timestamps.

The hub's syslog parser attempts to parse each message according to RFC~5424. When parsing fails, the message is logged locally (for debugging) but not forwarded to the server. A counter increments in the ``Parse Errors'' statistic displayed on the dashboard.

The system continues processing valid messages without interruption. The user can investigate the parse errors through the log viewer panel and identify the problematic source.

\subsubsection{Scenario 6: Server Overload Protection}

During a large-scale attack (e.g., DDoS), multiple clients simultaneously send high volumes of events to the server. The server's processing capacity is exceeded.

The server implements backpressure through its thread pool and bounded queue. When the queue reaches capacity, new batches are rejected with a ``SERVER\_BUSY'' response. Clients receiving this response reduce their transmission rate (additive decrease) and retry after a delay.

Additionally, the server prioritises HEARTBEAT messages over BATCH\_EVENT to maintain connection liveness. Clients that cannot transmit events queue them locally. When the load subsides, normal processing resumes without data loss (within buffer limits).

%==============================================================================
\section{Conclusion}
%==============================================================================

This work presents NMS, a modular client--server platform for network monitoring and security incident prevention. The system successfully addresses the requirements of centralised log collection, real-time anomaly detection, multi-user privacy isolation, and integration with third-party infrastructure.

The three-tier architecture (Server, Client, Agent) provides clear separation of concerns. The server handles computationally intensive ML inference without storing sensitive client data beyond what is necessary for processing. Clients act as autonomous monitoring hubs for their local networks, aggregating events from custom agents and standard syslog sources. Lightweight agents minimise resource consumption on monitored endpoints.

The integration of LogBERT through ONNX Runtime demonstrates that modern transformer-based anomaly detection can be deployed in production C++ systems with acceptable performance. The native Dear ImGui dashboard provides real-time visualisation without the complexity of web-based interfaces.

\subsection{Potential Improvements}

Several enhancements could extend the platform's capabilities:

\begin{itemize}
  \item \textbf{Authentication System}: Replace IP-based identification with token-based authentication, enabling users to access their data from different networks and supporting multiple networks per account.
  \item \textbf{Distributed Server Architecture}: Deploy multiple server instances behind a load balancer to handle larger client populations and provide high availability.
  \item \textbf{Enhanced ML Pipeline}: Add incremental model retraining based on user feedback (confirmed true/false positives), improving detection accuracy over time.
  \item \textbf{Elastic/OpenSearch Integration}: Optionally export processed events to Elastic Stack for advanced querying, long-term retention, and integration with existing SIEM workflows.
  \item \textbf{Mobile Dashboard}: Develop a companion mobile application for alert notifications and basic monitoring when away from the primary workstation.
  \item \textbf{Encrypted Agent Communication}: Add optional TLS for agent--hub communication in zero-trust network environments.
  \item \textbf{Windows Native Agent}: Extend agent support to Windows Event Log collection with native API integration.
\end{itemize}

The modular architecture ensures that these improvements can be implemented incrementally without redesigning the core platform.

%==============================================================================
\begin{thebibliography}{99}

\bibitem{rfc5424}
Gerhards, R.: The Syslog Protocol. RFC 5424, Internet Engineering Task Force (IETF) (2009). \url{https://www.rfc-editor.org/rfc/rfc5424}

\bibitem{tcpip}
Stevens, W.R.: TCP/IP Illustrated, Volume 1: The Protocols. Addison-Wesley (1994).

\bibitem{stallings}
Stallings, W.: Network Security Essentials: Applications and Standards. 6th edn. Pearson (2017).

\bibitem{onnx}
ONNX Project: Open Neural Network Exchange. \url{https://onnx.ai}. Accessed: 28 November 2025.

\bibitem{onnxruntime}
Microsoft: ONNX Runtime -- High Performance ML Inferencing. \url{https://onnxruntime.ai}. Accessed: 28 November 2025.

\bibitem{logbert}
Guo, H., Yuan, S., Wu, X.: LogBERT: Log Anomaly Detection via BERT. In: International Joint Conference on Neural Networks (IJCNN), pp. 1--8. IEEE (2021).

\bibitem{docker}
Merkel, D.: Docker: Lightweight Linux Containers for Consistent Development and Deployment. Linux Journal, 2014(239) (2014).

\bibitem{sqlite}
SQLite Consortium: SQLite Documentation. \url{https://www.sqlite.org/docs.html}. Accessed: 28 November 2025.

\bibitem{openssl}
OpenSSL Project: OpenSSL Cryptography and SSL/TLS Toolkit. \url{https://www.openssl.org}. Accessed: 28 November 2025.

\bibitem{imgui}
Cornut, O.: Dear ImGui -- Bloat-free Graphical User Interface for C++. \url{https://github.com/ocornut/imgui}. Accessed: 28 November 2025.

\bibitem{wazuh}
Wazuh, Inc.: Wazuh -- The Open Source Security Platform. \url{https://wazuh.com}. Accessed: 28 November 2025.

\bibitem{elastic}
Elastic N.V.: Elastic Security -- SIEM, Endpoint Security, and Cloud Security. \url{https://www.elastic.co/security}. Accessed: 28 November 2025.

\bibitem{nlohmann}
Lohmann, N.: JSON for Modern C++. \url{https://github.com/nlohmann/json}. Accessed: 28 November 2025.

\bibitem{siem}
Scarfone, K., Mell, P.: Guide to Intrusion Detection and Prevention Systems (IDPS). NIST Special Publication 800-94 (2007).

\bibitem{xgboost}
Chen, T., Guestrin, C.: XGBoost: A Scalable Tree Boosting System. In: Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 785--794. ACM (2016).

\end{thebibliography}

\end{document}
